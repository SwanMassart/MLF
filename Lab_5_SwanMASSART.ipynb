{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNO78RhsnL9leJUeR6CkSSm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SwanMassart/MLF/blob/main/lab5_SwanMASSART.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyOA_HIlaHOc"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Mar 11 08:59:13 2025\n",
        "\n",
        "@author: Swan\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, InputLayer\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
        "y = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(InputLayer(shape=(2,)))\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(X, y, epochs=1000, batch_size=1, verbose=0)\n",
        "\n",
        "\n",
        "loss, accuracy = model.evaluate(X, y, verbose=0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "#  Expérimentation\n",
        "\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
        "y = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
        "\n",
        "\n",
        "epochs_list = [200, 1000, 5000]  # Nombre d'époques\n",
        "learning_rates = [0.01, 0.1, 0.5]  # Taux d'apprentissage\n",
        "activation_functions = ['sigmoid', 'relu', 'tanh']  # Activation\n",
        "batch_sizes = [1, 4, 6]  # Batch size\n",
        "num_neurons_list = [2, 4, 8]  # Nombre de neurones dans la couche cachée\n",
        "verbose_mode = 0  # (0 = silencieux, 1 = affichage détaillé)\n",
        "\n",
        "\n",
        "for epochs in epochs_list:\n",
        "    for lr in learning_rates:\n",
        "        for activation in activation_functions:\n",
        "            for batch_size in batch_sizes:\n",
        "                for num_neurons in num_neurons_list:\n",
        "\n",
        "                    # Création du modèle\n",
        "                    model = Sequential([\n",
        "                        Input(shape=(2,)),\n",
        "                        Dense(num_neurons, activation=activation),\n",
        "                        Dense(1, activation='sigmoid')\n",
        "                    ])\n",
        "\n",
        "                    # Compilation avec l'optimiseur Adam\n",
        "                    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "                    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "                    # Entraînement\n",
        "                    history = model.fit(X, y, epochs=epochs, batch_size=batch_size, verbose=verbose_mode)\n",
        "\n",
        "                    # Évaluation finale\n",
        "                    loss, accuracy = model.evaluate(X, y, verbose=0)\n",
        "\n",
        "                    # Résultats\n",
        "                    print(f\"\\n Configuration testée :\")\n",
        "                    print(f\"   Epochs: {epochs} |  Learning Rate: {lr} |  Activation: {activation}\")\n",
        "                    print(f\"   Batch Size: {batch_size} |  Neurons: {num_neurons}\")\n",
        "                    print(f\"  Final Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "                    #  Affichage de la courbe de perte\n",
        "                    plt.figure()\n",
        "                    plt.plot(history.history['loss'])\n",
        "                    plt.xlabel('Epochs')\n",
        "                    plt.ylabel('Loss')\n",
        "                    plt.title(f'Loss (Epochs={epochs}, LR={lr}, Act={activation}, Batch={batch_size}, Neurons={num_neurons})')\n",
        "                    plt.show()\n",
        "print('Accuracy: {:.2f}'.format(accuracy*100))\n",
        "\n",
        "for id_x, data_sample in enumerate(X):\n",
        "  prediction = model.predict(data_sample.reshape(1, -1))\n",
        "  print(f\"Data sample is {data_sample}, prediction from model {prediction}, ground_truth {y[id_x]}\")\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.xlabel('n epochs')\n",
        "plt.ylabel('loss')\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Exercise 2 - Congressional Voting Data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Mar 11 09:54:18 2025\n",
        "\n",
        "@author: Swan\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "path_to_dataset = 'voting_complete.csv'\n",
        "pd_dataset = pd.read_csv(path_to_dataset)\n",
        "\n",
        "print(pd_dataset.head())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def custom_train_test_split(pd_data: pd.DataFrame, test_ratio: float = 0.2) -> tuple:\n",
        "    pd_dataset = pd_data.copy()\n",
        "    index = np.arange(len(pd_dataset))\n",
        "    np.random.shuffle(index)\n",
        "\n",
        "    train_amount = int(len(index) * (1 - test_ratio))\n",
        "    train_ids, test_ids = index[:train_amount], index[train_amount:]\n",
        "\n",
        "    train_dataset = pd_dataset.iloc[train_ids].reset_index(drop=True)\n",
        "    test_dataset = pd_dataset.iloc[test_ids].reset_index(drop=True)\n",
        "\n",
        "    X_train, y_train = train_dataset.iloc[:, 1:], train_dataset.iloc[:, 0]\n",
        "    X_test, y_test = test_dataset.iloc[:, 1:], test_dataset.iloc[:, 0]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "\n",
        "x_train, y_train, x_test, y_test = custom_train_test_split(pd_dataset)\n",
        "\n",
        "\n",
        "x_train.replace({'y': 1, 'n': 0, '?': np.nan}, inplace=True)\n",
        "x_test.replace({'y': 1, 'n': 0, '?': np.nan}, inplace=True)\n",
        "\n",
        "\n",
        "x_train.fillna(x_train.mode().iloc[0], inplace=True)\n",
        "x_test.fillna(x_test.mode().iloc[0], inplace=True)\n",
        "\n",
        "\n",
        "x_train = pd.get_dummies(x_train, dtype=int)\n",
        "x_test = pd.get_dummies(x_test, dtype=int)\n",
        "\n",
        "\n",
        "x_test = x_test.reindex(columns=x_train.columns, fill_value=0)\n",
        "\n",
        "\n",
        "y_train = y_train.replace({'Republican': 0, 'Democrat': 1})\n",
        "y_test = y_test.replace({'Republican': 0, 'Democrat': 1})\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(32, input_shape=(x_train.shape[1],), activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)  # Réduction du learning rate\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=8,  # Augmentation du batch_size pour plus de stabilité\n",
        "                    verbose=1,\n",
        "                    validation_data=(X_val, y_val))\n",
        "\n",
        "# Évaluation du modèle\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f'Model Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if 'loss' in history.history and 'val_loss' in history.history:\n",
        "    # Création de la figure pour la perte\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Erreur \")\n",
        "\n",
        "if 'accuracy' in history.history and 'val_accuracy' in history.history:\n",
        "    # Création de la figure pour l'accuracy\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Erreur \")"
      ]
    }
  ]
}
